{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import Packages and Libraries ##\n",
    "\n",
    "# Web parcing, scraping, etc.\n",
    "import bs4 as bs # BeautifulSoup4 \n",
    "import urllib3\n",
    "import re\n",
    "import requests # HTTP parser\n",
    "import html5lib\n",
    "\n",
    "# DataFrames and math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Output related packages \n",
    "import pprint as pp\n",
    "import json\n",
    "\n",
    "# Progress bar and delaying requests \n",
    "# from tqdm import tnrange, tqdm_notebook #progress bars\n",
    "from random import randint\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:90% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# stretch Jupyter coding blocks to fit screen\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:90% !important; }</style>\")) \n",
    "\n",
    "# make it run on py2 and py3\n",
    "from __future__ import division, print_function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Mining I\n",
    "This  notebook is intended to perform the following processes:\n",
    "\n",
    "    1.1 Read-in news articles from newsAPI for a given date range, and up to five queries (passed as a list).\n",
    "\n",
    "    1.2 Extract features native to the articles (e.g. url).\n",
    "\n",
    "    1.3 Perform data cleanup and preprocessing.\n",
    "\n",
    "    1.4 Split dataset into n-csv-files for distrubuted computation or batching."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __Documentation__\n",
    "\n",
    "newsAPI (https://newsapi.org/) has limited documentation as to how their backend works. However, when developing this notebook the following website was frequently referenced -- as their documentation appears to closely match the behavior of newsAPI. \n",
    "\n",
    "https://docs.aylien.com/newsapi/#getting-started\n",
    "\n",
    "Moreover, here is the user agreement:\n",
    "\n",
    "https://newsapi.org/terms\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### **Begin Data Mining I:** Read-in NewsAPI feed for a given date range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'newsapi.newsapi_client.NewsApiClient'>\n"
     ]
    }
   ],
   "source": [
    "### NEWSAPI RELATED ###\n",
    "# keys: \n",
    "#rhkey = '847446b32283474fafd2aec7f95e502b'\n",
    "#r1key  = '1da951c142304f7bab52ba8e3970495b'\n",
    "#r2key = '40d53e49ee3543a3b162e6a453e2e373'\n",
    "m1key = '211fc2107848473e99c1f235b400a07f'\n",
    "# m2key = 'c0f99eab932d4cabb61c23239f3f482d'\n",
    "# m3key = '658cd65a714349fdbb7e8dd6ce59e9c4'\n",
    "#m4key  = '8ba091b7a47b4c9a9162a83ca72eb1ca'\n",
    "#e1key  = '2bc85776a0c14af6b9937366ad683e2f'\n",
    "#e2key = '22e5c3a8f0ee4fa59aaf384ba9395a86'\n",
    "#e3key = 'c554f8fb27ca4be1862192b44ee4425d'\n",
    "\n",
    "\n",
    "# Install API \n",
    "# !pip install newsapi-python\n",
    "\n",
    "# Import Client\n",
    "from newsapi import NewsApiClient\n",
    "\n",
    "# Initialize Client (create object)\n",
    "news_api = NewsApiClient(api_key = m1key)\n",
    "print(type(news_api))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1.1 Read-in news articles from newsAPI for a given date range__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function: **get_news**\n",
    "Function establishes values to be used for control of loop then calls functions used to extract news article data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_news(query, start, stop, sort, lang, article_count, page_count, init):\n",
    "    \"\"\"\n",
    "    control function for iterating over 100 pages of newsAPI's content \n",
    "    function then controls subordinate fuctions that extract ~100 articles per each page\n",
    "    \"\"\"\n",
    "    \n",
    "    import math\n",
    "    import time  \n",
    "    \n",
    "    # extract information about response file to ensure proper loop control\n",
    "    params = get_params(query, start, stop, sort, lang, article_count, page_count)\n",
    "\n",
    "    # variable referencing\n",
    "    status = params['status']\n",
    "    results = params['totalResults']\n",
    "\n",
    "    # Confirmation of data extraction\n",
    "    print(\"\\nVerify Read-in Process:\", status)\n",
    "    print(\"Number of Articles Correctly Read: \", results)\n",
    "    print(type(params), params.keys())\n",
    "           \n",
    "    # per page article extraction stop variable -- if number of articles is greater than number articles per page\n",
    "    loops = math.ceil(results/article_count)\n",
    "    \n",
    "    # batching control\n",
    "    begin = 0 + init\n",
    "    terminate = article_count + init\n",
    "    print(\"Total number of iterations (pages):\",loops)\n",
    "    \n",
    "    # check to ensure loop does not extract over 100pages*100endpoints=10000 articles\n",
    "    if loops < terminate:\n",
    "        terminate = loops\n",
    "        \n",
    "    print(\"Page range being extracted\", begin, terminate)\n",
    "    \n",
    "    if page_count == 'all' or article_count <  results:\n",
    "        print(\"\\n\\nExtracting News Data...\\n\")\n",
    "        full_df = pd.DataFrame()\n",
    "    \n",
    "        # function is called withinin while, is subject to number of pages available as a function of total no. articles\n",
    "        while begin < terminate:\n",
    "            begin += 1\n",
    "            page = begin  # for referencing clarity\n",
    "            \n",
    "            ### newsAPI has MAX HIT LIMIT of 60 per minute ### \n",
    "            time.sleep(1)   # delay of 1 second\n",
    "            print(\"Extracting Page\", page)\n",
    "\n",
    "            # call sequencial pages of articles and appends to df\n",
    "            df = news_data(query, start, stop, sort, lang, article_count, page)\n",
    "            full_df = full_df.append(df, ignore_index = True)\n",
    "            \n",
    "        print('Batch extraction completed:',begin,'of',terminate)\n",
    "        return(full_df)            \n",
    "    else:\n",
    "        # extracts articles assuming articles >= pages\n",
    "        print(\"Possible Invalid Parameters: Check values\")\n",
    "        brief_df = news_api.get_everything(q = query,\n",
    "                                          from_parameter= start,\n",
    "                                          to= stop,\n",
    "                                          sort_by= sort,\n",
    "                                          language= lang,\n",
    "                                          page_size= int(article_count)\n",
    "                                         )\n",
    "        return(brief_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function: **get_params**\n",
    "Function runs an initial newsAPI call, used to store values for controlling loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params(query, start, stop, sort, lang, article_count, page_count):\n",
    "    \"\"\"\n",
    "    function accepts similar parameters to master function get_news.\n",
    "    get_params is used to extract parameters to be used in controlling other functions \n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nExtracting Parameters for newsAPI...\\n\")\n",
    "    params = news_api.get_everything(q = query,\n",
    "                                     from_param= start,\n",
    "                                     to= stop,\n",
    "                                     sort_by= sort,\n",
    "                                     language= lang,\n",
    "                                     page_size= int(article_count)\n",
    "                                    )\n",
    "    \n",
    "    # Confirmation of data extraction\n",
    "    print(\"Read-in Status of Given Date Range:\", params['status'])\n",
    "    print(\"Number of Articles in Given Date Range: \", params['totalResults'])\n",
    "    \n",
    "    return(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function: **news_data**\n",
    "Function handles cases, and extracts values within 'articles'. Returns dataframe of contents: \n",
    "\n",
    "\n",
    "*Index(['author', 'description', 'publishedAt', 'source', 'title', 'url','urlToImage'],dtype='object')*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def news_data(query, start, stop, sort, lang, article_count, page):\n",
    "    \"\"\"\n",
    "    Principal data extraction function - can handle various relationships between no.pages and no.articles \n",
    "    \"\"\"\n",
    "    \n",
    "    if isinstance(page, int):\n",
    "        params = news_api.get_everything(q = query,\n",
    "                                         from_param= start,\n",
    "                                         to= stop,\n",
    "                                         sort_by= sort,\n",
    "                                         language= lang,\n",
    "                                         page_size= int(article_count),\n",
    "                                         page = int(page)\n",
    "                                        )\n",
    "    ########### if params['articles'] throws error ########### \n",
    "    # either endpoint limit was met (10000)                  #\n",
    "    # too many endpoint requests in a month (1000 per month) #\n",
    "    # change to new api key.                                 #\n",
    "    ##########################################################\n",
    "    return(pd.DataFrame(params['articles'])) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### User provided parameters and function call."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#01/26/18 to 03/26/18\n",
    "query = 'Bitcoin'         # can handle a list of up to five search topics\n",
    "start = '2018-10-09'      # yyyy-mm-dd\n",
    "stop  = '2018-10-14'\n",
    "sort  = 'publishedAt'\n",
    "lang  = 'en'\n",
    "article_count = 100       # default is 20\n",
    "page_count = 'all'        # enter 1, 2, ... Notes: 'all' iterates over all articLes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "---\n",
    "#### __NOTE__\n",
    "\n",
    "Since newsAPI has a daily limit of endpoint requests (1000 per day), batching needs to be implemented.  The following cells controls the initialization for subsequent cells -- to ensure appropropriate, and sequential article extraction.\n",
    "\n",
    "Also, webAPI has a limit of 10,000 articles per key -- unless you want to pay for the monthly access.\n",
    "___\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## ---------------------------------------------------------------------------- ##\n",
    "## KEY: Initialize accroding to batch number (i.e. n*100, where n is the batch) ##\n",
    "## USE: n > 0 ---- only once we can extract above 10000 articles\n",
    "n = 0\n",
    "init = n*100\n",
    "## ---------------------------------------------------------------------------- ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Extracting Parameters for newsAPI...\n",
      "\n",
      "Read-in Status of Given Date Range: ok\n",
      "Number of Articles in Given Date Range:  858\n",
      "\n",
      "Verify Read-in Process: ok\n",
      "Number of Articles Correctly Read:  858\n",
      "<class 'dict'> dict_keys(['status', 'totalResults', 'articles'])\n",
      "Total number of iterations (pages): 9\n",
      "Page range being extracted 0 9\n",
      "\n",
      "\n",
      "Extracting News Data...\n",
      "\n",
      "Extracting Page 1\n",
      "Extracting Page 2\n",
      "Extracting Page 3\n",
      "Extracting Page 4\n",
      "Extracting Page 5\n",
      "Extracting Page 6\n",
      "Extracting Page 7\n",
      "Extracting Page 8\n",
      "Extracting Page 9\n",
      "Batch extraction completed: 9 of 9\n"
     ]
    }
   ],
   "source": [
    "# object is the result of the following functions: 'get_params', 'get_news', and 'get_data'\n",
    "news = get_news(query, start, stop, sort, lang, article_count, page_count, init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore nested key/value pairs from newsAPI data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['author', 'content', 'description', 'publishedAt', 'source', 'title',\n",
       "       'url', 'urlToImage'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## ENSURE API WAS ACCESSED ##\n",
    "# if news.keys includes 'author', 'description', etc., success!\n",
    "\n",
    "news.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "858\n",
      "Index(['author', 'content', 'description', 'publishedAt', 'source', 'title',\n",
      "       'url', 'urlToImage'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "854"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(news))\n",
    "print(news.keys())\n",
    "news.head(5)\n",
    "len(news['url'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1.2 Extract features native to the articles__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function: **get_info**\n",
    "Function extracts variables from dataframe and stores each as a list, returning all of them as a single dataframe.\n",
    "\n",
    "__Note:__ *urlToImage* is not included in this process, as we are uncertain as to the value of the feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(df):\n",
    "    \"\"\"\n",
    "    Accepts a dataframe of newsAPI articles, and controls all subbordinate functions that preprocess data\n",
    "    \"\"\"\n",
    "    \n",
    "    import copy\n",
    "    \n",
    "    author = []\n",
    "    title = []\n",
    "    publisher = []\n",
    "    publish_url = []\n",
    "    timeStamp = []\n",
    "    content = []\n",
    "    \n",
    "    \n",
    "    # loop appends rows to respective lists \n",
    "    for col_name in df:\n",
    "        for index in df[col_name]:\n",
    "            if col_name == 'author':\n",
    "                author.append(index)\n",
    "            elif col_name == 'title':\n",
    "                title.append(index)\n",
    "            elif col_name == 'source':\n",
    "                name = index['name']\n",
    "                publisher.append(name)\n",
    "            elif col_name == 'url':\n",
    "                publish_url.append(index)\n",
    "            elif col_name == 'publishedAt':\n",
    "                timeStamp.append(index)\n",
    "            elif col_name == 'content':\n",
    "                content.append(index)\n",
    "            else:\n",
    "                continue\n",
    "    \n",
    "    # merge lists and return them as dataframe.\n",
    "    df = pd.DataFrame({'author' : author,\n",
    "                       'title' : title,\n",
    "                       'publisher' : publisher,\n",
    "                       'source_url' : publish_url,\n",
    "                       'timeStamp' : timeStamp,\n",
    "                       'content' : content})\n",
    "    \n",
    "    return(df)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Completed newsAPI Read-in Process: \n",
    "##### newsDF contains features extracted from raw newsAPI feed, for a given data range, and query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Object creation\n",
    "newsDF = get_info(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DataFrame Dimensions: (858, 6) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>publisher</th>\n",
       "      <th>source_url</th>\n",
       "      <th>timeStamp</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Tyler Durden</td>\n",
       "      <td>Internet Censorship Just Took An Unprecedented...</td>\n",
       "      <td>Zerohedge.com</td>\n",
       "      <td>https://www.zerohedge.com/news/2018-10-14/inte...</td>\n",
       "      <td>2018-10-15T00:00:00Z</td>\n",
       "      <td>Authored by Cailtin Johnstone via Medium.com, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Osato Avan-Nomayo</td>\n",
       "      <td>Bitcoin Mining: Three Reasons Why Energy Consu...</td>\n",
       "      <td>Bitcoinist.com</td>\n",
       "      <td>https://bitcoinist.com/bitcoin-mining-three-re...</td>\n",
       "      <td>2018-10-14T23:00:47Z</td>\n",
       "      <td>When they aren’t bashing Bitcoin as a bubble, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>James Mickleboro</td>\n",
       "      <td>Bitcoin, Ethereum, and Ripple mixed after Dr D...</td>\n",
       "      <td>Fool.com.au</td>\n",
       "      <td>https://www.fool.com.au/2018/10/15/bitcoin-eth...</td>\n",
       "      <td>2018-10-14T21:30:51Z</td>\n",
       "      <td>It has been a reasonably subdued weekend of tr...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              author                                              title  \\\n",
       "0       Tyler Durden  Internet Censorship Just Took An Unprecedented...   \n",
       "1  Osato Avan-Nomayo  Bitcoin Mining: Three Reasons Why Energy Consu...   \n",
       "2   James Mickleboro  Bitcoin, Ethereum, and Ripple mixed after Dr D...   \n",
       "\n",
       "        publisher                                         source_url  \\\n",
       "0   Zerohedge.com  https://www.zerohedge.com/news/2018-10-14/inte...   \n",
       "1  Bitcoinist.com  https://bitcoinist.com/bitcoin-mining-three-re...   \n",
       "2     Fool.com.au  https://www.fool.com.au/2018/10/15/bitcoin-eth...   \n",
       "\n",
       "              timeStamp                                            content  \n",
       "0  2018-10-15T00:00:00Z  Authored by Cailtin Johnstone via Medium.com, ...  \n",
       "1  2018-10-14T23:00:47Z  When they aren’t bashing Bitcoin as a bubble, ...  \n",
       "2  2018-10-14T21:30:51Z  It has been a reasonably subdued weekend of tr...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Verifying correct data extraction\n",
    "print(\"\\nDataFrame Dimensions:\", newsDF.shape, \"\\n\")\n",
    "newsDF.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1.3 Perform data cleanup and preprocessing.__\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following functions perform basic clean up on a dataframe. The purpose is to prepare the file to write-out (csv).  \n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace 'None' values\n",
    "def findNone(df):\n",
    "    \"\"\"\n",
    "     Receives pandas datraframe, and removes null entries from author feature\n",
    "    \"\"\"\n",
    "    print(\"Removed 'None' values in author feature...\")\n",
    "    author = df['author']\n",
    "    publisher = df['publisher']\n",
    "    \n",
    "    for i in range(len(df)):\n",
    "        if pd.isnull(author.loc[i]):\n",
    "            author.loc[i] = publisher.loc[i]\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove gaps \n",
    "def gapStrip(df):\n",
    "    \"\"\"\n",
    "    Receives pandas dataframe and leading and traling empty space`\n",
    "    \"\"\"\n",
    "    df.columns = map(str.strip, df.columns) \n",
    "    print(\"Removed leading and trailing spaces and tabs...\")\n",
    "    # element-wise operation\n",
    "    f = lambda x: x.strip() if (isinstance(x,str)) else x\n",
    "    df = df.applymap(f)\n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize time stamps\n",
    "def std_timeStamp(df):\n",
    "    \"\"\"\n",
    "    Receives pandas dataframe and standardizes time stamps \n",
    "    \"\"\"\n",
    "    import datetime\n",
    "    # Check to see time stamps are in zero timezones\n",
    "    print(\"Converted Time Stamps to Desired Standard Formating...\")\n",
    "    for time in df['timeStamp']:\n",
    "        if time.endswith('Z'):\n",
    "            df['timeStamp'] = pd.to_datetime(df['timeStamp'],\n",
    "                                             infer_datetime_format = True,\n",
    "                                             utc = True)                       # returns a type '.Timestamp'\n",
    "            return(df)\n",
    "        else:\n",
    "            print(\"Revisit appropriate variable or function to deal with time zones that are not zero\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_clean(df):\n",
    "    \"\"\"\n",
    "    Performs Generic Cleanup and Preprocessing on a given dataframe sourced from newsAPI\n",
    "    \"\"\"\n",
    "    \n",
    "    temp = findNone(df)           # removes missing values from author column\n",
    "    temp2 = gapStrip(temp)        # remove leading and trailing white space\n",
    "    temp3 = std_timeStamp(temp2)  # convert time stamps to 'utc' standard\n",
    "    return(temp3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 'None' values in author feature...\n",
      "Removed leading and trailing spaces and tabs...\n",
      "Converted Time Stamps to Desired Standard Formating...\n"
     ]
    }
   ],
   "source": [
    "riskEx_df = feature_clean(newsDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(              author                                              title  \\\n",
       " 0       Tyler Durden  Internet Censorship Just Took An Unprecedented...   \n",
       " 1  Osato Avan-Nomayo  Bitcoin Mining: Three Reasons Why Energy Consu...   \n",
       " 2   James Mickleboro  Bitcoin, Ethereum, and Ripple mixed after Dr D...   \n",
       " 3         Yashu Gola  Report: Crypto Funds Make up 20% of Hedge Fund...   \n",
       " 4          besguerra  PH energy firms ready to adopt blockchain tech...   \n",
       " \n",
       "            publisher                                         source_url  \\\n",
       " 0      Zerohedge.com  https://www.zerohedge.com/news/2018-10-14/inte...   \n",
       " 1     Bitcoinist.com  https://bitcoinist.com/bitcoin-mining-three-re...   \n",
       " 2        Fool.com.au  https://www.fool.com.au/2018/10/15/bitcoin-eth...   \n",
       " 3  Crypto Coins News  https://www.ccn.com/report-crypto-funds-makes-...   \n",
       " 4       Inquirer.net  https://business.inquirer.net/258968/ph-energy...   \n",
       " \n",
       "                   timeStamp                                            content  \n",
       " 0 2018-10-15 00:00:00+00:00  Authored by Cailtin Johnstone via Medium.com, ...  \n",
       " 1 2018-10-14 23:00:47+00:00  When they aren’t bashing Bitcoin as a bubble, ...  \n",
       " 2 2018-10-14 21:30:51+00:00  It has been a reasonably subdued weekend of tr...  \n",
       " 3 2018-10-14 21:03:13+00:00  The number of cryptocurrency hedge fund launch...  \n",
       " 4 2018-10-14 21:02:03+00:00  The blockchain business is expected to explode...  ,\n",
       "                         author  \\\n",
       " 853                  Tim Smith   \n",
       " 854                  Wilma Woo   \n",
       " 855              Bart Anderson   \n",
       " 856  Jay Weaver, By Jay Weaver   \n",
       " 857            Auer, Claessens   \n",
       " \n",
       "                                                  title         publisher  \\\n",
       " 853              5 Canadian Fintech Companies to Watch  Investopedia.com   \n",
       " 854  Venezuela Bitcoin Trading Hits New Record As M...    Bitcoinist.com   \n",
       " 855                          Hidden Costs – 8 Oct 2018    Resilience.org   \n",
       " 856  ‘Oxymonster’ sentenced to 20 years for drug de...  Bostonherald.com   \n",
       " 857  Regulating cryptocurrencies: Assessing market ...         Voxeu.org   \n",
       " \n",
       "                                             source_url  \\\n",
       " 853  https://www.investopedia.com/articles/markets/...   \n",
       " 854  https://bitcoinist.com/venezuela-bitcoin-tradi...   \n",
       " 855  https://www.resilience.org/stories/2018-10-09/...   \n",
       " 856  http://www.bostonherald.com/news/national/2018...   \n",
       " 857  https://voxeu.org/article/regulating-cryptocur...   \n",
       " \n",
       "                     timeStamp  \\\n",
       " 853 2018-10-09 01:26:00+00:00   \n",
       " 854 2018-10-09 01:00:22+00:00   \n",
       " 855 2018-10-09 00:11:10+00:00   \n",
       " 856 2018-10-09 00:00:00+00:00   \n",
       " 857 2018-10-09 00:00:00+00:00   \n",
       " \n",
       "                                                content  \n",
       " 853  Although Canada does not receive the same kudo...  \n",
       " 854  Venezuela posted its largest-ever Bitcoin trad...  \n",
       " 855  A roundup of news, views and ideas from the ma...  \n",
       " 856  MIAMI — He got his nickname, “Oxymonster,” for...  \n",
       " 857  Cryptocurrencies are often thought to operate ...  )"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ensure data was preprocessed\n",
    "riskEx_df.head(5), riskEx_df.tail(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 858 entries, 0 to 857\n",
      "Data columns (total 6 columns):\n",
      "author        858 non-null object\n",
      "title         858 non-null object\n",
      "publisher     858 non-null object\n",
      "source_url    858 non-null object\n",
      "timeStamp     858 non-null datetime64[ns, UTC]\n",
      "content       820 non-null object\n",
      "dtypes: datetime64[ns, UTC](1), object(5)\n",
      "memory usage: 40.3+ KB\n"
     ]
    }
   ],
   "source": [
    "## Check file size\n",
    "riskEx_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__1.4 Write out to csv.__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write out n-csv-files each with 100 rows. Process is done to reduce computational load\n",
    "riskEx_df.to_csv('rawData_test1006.csv', index_label = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "858\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "781"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('rawData_test1006.csv')\n",
    "#print(df.info())\n",
    "print(len(df))\n",
    "len(df['content'].unique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(df['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['content'].dropna(axis = 0,inplace = True)\n",
    "# df[df['description'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author        Davey Winder, Contributor, Davey Winder, Contr...\n",
       "title         Schrodinger's Encryption: What The CISO Needs ...\n",
       "publisher                                            Forbes.com\n",
       "source_url    https://www.forbes.com/sites/daveywinder/2018/...\n",
       "timeStamp                             2018-10-12 10:11:00+00:00\n",
       "content       There's a brilliant Dilbert cartoon where the ...\n",
       "Name: 241, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df[df['description'].isnull()]\n",
    "df.iloc[241,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = vectorizer.fit(df['content'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_of_words = vectorizer.transform(df['content'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>0007</th>\n",
       "      <th>000who</th>\n",
       "      <th>0038</th>\n",
       "      <th>0058</th>\n",
       "      <th>01</th>\n",
       "      <th>02</th>\n",
       "      <th>03</th>\n",
       "      <th>05</th>\n",
       "      <th>...</th>\n",
       "      <th>zencash</th>\n",
       "      <th>zero</th>\n",
       "      <th>zipped</th>\n",
       "      <th>zoe</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombies</th>\n",
       "      <th>zone</th>\n",
       "      <th>zrx</th>\n",
       "      <th>zug</th>\n",
       "      <th>zuoxing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 6713 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  000  0007  000who  0038  0058  01  02  03  05   ...     zencash  zero  \\\n",
       "0   0    0     0       0     0     0   0   0   0   0   ...           0     0   \n",
       "1   0    0     0       0     0     0   0   0   0   0   ...           0     0   \n",
       "2   0    0     0       0     0     0   0   0   0   0   ...           0     0   \n",
       "3   0    0     0       0     0     0   0   0   0   0   ...           0     0   \n",
       "4   0    0     0       0     0     0   0   0   0   0   ...           0     0   \n",
       "\n",
       "   zipped  zoe  zombie  zombies  zone  zrx  zug  zuoxing  \n",
       "0       0    0       0        0     0    0    0        0  \n",
       "1       0    0       0        0     0    0    0        0  \n",
       "2       0    0       0        0     0    0    0        0  \n",
       "3       0    0       0        0     0    0    0        0  \n",
       "4       0    0       0        0     0    0    0        0  \n",
       "\n",
       "[5 rows x 6713 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_cor = pd.DataFrame(bag_of_words.toarray(), columns=vectorizer.get_feature_names())\n",
    "words_cor.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the                 1925\n",
       "to                   842\n",
       "of                   835\n",
       "chars                804\n",
       "and                  663\n",
       "in                   639\n",
       "is                   426\n",
       "on                   320\n",
       "for                  320\n",
       "bitcoin              316\n",
       "has                  286\n",
       "that                 273\n",
       "as                   269\n",
       "cryptocurrency       229\n",
       "with                 207\n",
       "this                 195\n",
       "are                  193\n",
       "by                   179\n",
       "it                   178\n",
       "at                   170\n",
       "its                  169\n",
       "from                 167\n",
       "an                   144\n",
       "have                 142\n",
       "crypto               142\n",
       "market               139\n",
       "blockchain           129\n",
       "was                  113\n",
       "new                  112\n",
       "be                   108\n",
       "                    ... \n",
       "invites                1\n",
       "inviting               1\n",
       "iota                   1\n",
       "ip                     1\n",
       "ipfs                   1\n",
       "intellia               1\n",
       "iphone                 1\n",
       "ipo                    1\n",
       "ipv6                   1\n",
       "irans                  1\n",
       "ironic                 1\n",
       "irrational             1\n",
       "investigate            1\n",
       "inversely              1\n",
       "introducing            1\n",
       "introduce              1\n",
       "intractable            1\n",
       "intra                  1\n",
       "intolerant             1\n",
       "interviewer            1\n",
       "interspaced            1\n",
       "intersection           1\n",
       "interoperability       1\n",
       "interna                1\n",
       "interbank              1\n",
       "interactions           1\n",
       "intention              1\n",
       "intensified            1\n",
       "intended               1\n",
       "harvey                 1\n",
       "Length: 6713, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words_cor.sum().sort_values(ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['the', 'to', 'of', 'chars', 'and', 'in', 'is', 'on', 'for', 'bitcoin',\n",
       "       ...\n",
       "       'interspaced', 'intersection', 'interoperability', 'interna',\n",
       "       'interbank', 'interactions', 'intention', 'intensified', 'intended',\n",
       "       'harvey'],\n",
       "      dtype='object', length=6713)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "asc = words_cor.sum().sort_values(ascending = False).index\n",
    "asc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(words_cor.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtt = words_cor.sum().to_frame(\"freq\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>chars</th>\n",
       "      <td>804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bitcoin</th>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cryptocurrency</th>\n",
       "      <td>229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>crypto</th>\n",
       "      <td>142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>market</th>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>blockchain</th>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>price</th>\n",
       "      <td>101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018</th>\n",
       "      <td>93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>first</th>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>one</th>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trading</th>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>us</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>exchange</th>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cryptocurrencies</th>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>company</th>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>markets</th>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>year</th>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>share</th>\n",
       "      <td>57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>today</th>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>digital</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>technology</th>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>million</th>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>data</th>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>investors</th>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>financial</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>week</th>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>industry</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>key</th>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>report</th>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>also</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>number</th>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tech</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>system</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>could</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>day</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>press</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ccn</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>way</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>back</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chart</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>still</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>people</th>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>much</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gt</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>stock</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>release</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>get</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>past</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>points</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>even</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>btc</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sell</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>co</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>network</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fund</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>oct</th>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  freq\n",
       "chars              804\n",
       "bitcoin            316\n",
       "cryptocurrency     229\n",
       "crypto             142\n",
       "market             139\n",
       "blockchain         129\n",
       "new                112\n",
       "price              101\n",
       "2018                93\n",
       "first               76\n",
       "one                 75\n",
       "trading             73\n",
       "us                  70\n",
       "exchange            70\n",
       "world               67\n",
       "cryptocurrencies    67\n",
       "company             65\n",
       "markets             64\n",
       "year                60\n",
       "share               57\n",
       "today               55\n",
       "digital             54\n",
       "technology          54\n",
       "million             53\n",
       "data                52\n",
       "investors           51\n",
       "financial           50\n",
       "week                50\n",
       "industry            47\n",
       "key                 47\n",
       "...                ...\n",
       "report              30\n",
       "also                29\n",
       "number              29\n",
       "tech                28\n",
       "system              28\n",
       "could               28\n",
       "day                 28\n",
       "press               28\n",
       "ccn                 28\n",
       "way                 28\n",
       "back                28\n",
       "chart               28\n",
       "still               28\n",
       "people              28\n",
       "much                27\n",
       "gt                  27\n",
       "losses              27\n",
       "stock               27\n",
       "release             27\n",
       "get                 27\n",
       "facebook            27\n",
       "past                26\n",
       "points              26\n",
       "even                26\n",
       "btc                 26\n",
       "sell                26\n",
       "co                  26\n",
       "network             25\n",
       "fund                25\n",
       "oct                 25\n",
       "\n",
       "[100 rows x 1 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered = [w for w in asc if not w in stop_words]\n",
    "freqs = words_cor[filtered].sum().to_frame(\"freq\")\n",
    "freqs = freqs[:100]\n",
    "freqs.to_csv('corporaZ*W.csv',index_label = False,index=False)\n",
    "freqs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ if wanting to create batches of raw data files containing n-articles, use the following"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def df_to_csvs(df):\n",
    "#    articlesPage = int(100)\n",
    "#    totalArticles = len(df)\n",
    "#    batchSize=round(totalArticles/articlesPage)          # number of rows in single output file\n",
    "        \n",
    "#    for id, df_i in  enumerate(np.array_split(df, batchSize)):\n",
    "#        df_i.to_csv('rawData_{id}.csv'.format(id=id), index_label = False)                 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **End Data Mining I:** Read-in NewsAPI feed for a given date range\n",
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
